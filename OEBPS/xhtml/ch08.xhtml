<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ns="http://www.w3.org/2001/10/synthesis" lang="en-us" xml:lang="en-us">
<head>
<title>Practical SQL: A Beginner’s Guide to Storytelling with Data</title>
<link href="../styles/9781593278458.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:c3d53d4c-356a-4b39-bef0-591c04016b72" name="Adept.expected.resource"/>
</head>
<body>
<h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_113"/><strong><span class="big">8</span></strong><br/><strong>EXTRACTING INFORMATION BY GROUPING AND SUMMARIZING</strong></h2>
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>
<p class="noindent">Every data set tells a story, and it’s the data analyst’s job to find out what that story is. In <a href="ch02.xhtml#ch02">Chapter 2</a>, you learned about interviewing data using <span class="literal">SELECT</span> statements, which included sorting columns, finding distinct values, and filtering results. You’ve also learned the fundamentals of SQL math, data types, table design, and joining tables. With all these tools under your belt, you’re ready to summarize data using grouping and SQL functions.</p>
<p class="indent">Summarizing data allows us to identify useful information we wouldn’t be able to see otherwise. In this chapter, we’ll use the well-known institution of your local library as our example.</p>
<p class="indent">Despite changes in the way people consume information, libraries remain a vital part of communities worldwide. But the internet and <span epub:type="pagebreak" id="page_114"/>advancements in library technology have changed how we use libraries. For example, ebooks and online access to digital materials now have a permanent place in libraries along with books and periodicals.</p>
<p class="indent">In the United States, the Institute of Museum and Library Services (IMLS) measures library activity as part of its annual Public Libraries Survey. The survey collects data from more than 9,000 library administrative entities, defined by the survey as agencies that provide library services to a particular locality. Some agencies are county library systems, and others are part of school districts. Data on each agency includes the number of branches, staff, books, hours open per year, and so on. The IMLS has been collecting data each year since 1988 and includes all public library agencies in the 50 states plus the District of Columbia and several territories, such as American Samoa. (Read more about the program at <em><a href="https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey/">https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey/</a></em>.)</p>
<p class="indent">For this exercise, we’ll assume the role of an analyst who just received a fresh copy of the library data set to produce a report describing trends from the data. We’ll need to create two tables, one with data from the 2014 survey and the second from the 2009 survey. Then we’ll summarize the more interesting data in each table and join the tables to see the five-year trends. During the analysis, you’ll learn SQL techniques for summarizing data using <em>aggregate functions</em> and <em>grouping</em>.</p>
<h3 class="h3" id="lev120">Creating the Library Survey Tables</h3>
<p class="noindent">Let’s create the 2014 and 2009 library survey tables and import the data. We’ll use appropriate data types for each column and add constraints and an index to each table to preserve data integrity and speed up queries.</p>
<h4 class="h4" id="lev121"><em>Creating the 2014 Library Data Table</em></h4>
<p class="noindent">We’ll start by creating the table for the 2014 library data. Using the <span class="literal">CREATE TABLE</span> statement, <a href="ch08.xhtml#ch08list1">Listing 8-1</a> builds <span class="literal">pls_fy2014_pupld14a</span>, a table for the fiscal year 2014 Public Library Data File from the Public Libraries Survey. The Public Library Data File summarizes data at the agency level, counting activity at all agency outlets, which include central libraries, branch libraries, and bookmobiles. The annual survey generates two additional files we won’t use: one summarizes data at the state level, and the other has data on individual outlets. For this exercise, those files are redundant, but you can read about the data they contain in the 2014 data dictionary, available from the IMLS at <em><a href="https://www.imls.gov/sites/default/files/fy2014_pls_data_file_documentation.pdf">https://www.imls.gov/sites/default/files/fy2014_pls_data_file_documentation.pdf</a></em>.</p>
<p class="indent">For convenience, I’ve created a naming scheme for the tables: <span class="literal">pls</span> refers to the survey title, <span class="literal">fy2014</span> is the fiscal year the data covers, and <span class="literal">pupld14a</span> is the name of the particular file from the survey. For simplicity, I’ve selected just 72 of the more relevant columns from the 159 in the original survey file to fill the <span class="literal">pls_fy2014_pupld14a</span> table, excluding data like the codes that explain the source of individual responses. When a library didn’t provide data, the agency derived the data using other means, but we don’t need that information for this exercise.</p>
<p class="indent"><span epub:type="pagebreak" id="page_115"/>Note that <a href="ch08.xhtml#ch08list1">Listing 8-1</a> is abbreviated for convenience. The full data set and code for creating and loading this table is available for download with all the book’s resources at <em><a href="https://www.nostarch.com/practicalSQL/">https://www.nostarch.com/practicalSQL/</a></em>.</p>
<p class="programs">  CREATE TABLE pls_fy2014_pupld14a (<br/>      stabr varchar(2) NOT NULL,<br/>    <span class="ent">➊</span> fscskey varchar(6) CONSTRAINT fscskey2014_key PRIMARY KEY,<br/>      libid varchar(20) NOT NULL,<br/>      libname varchar(100) NOT NULL,<br/>      obereg varchar(2) NOT NULL,<br/>      rstatus integer NOT NULL,<br/>      statstru varchar(2) NOT NULL,<br/>      statname varchar(2) NOT NULL,<br/>      stataddr varchar(2) NOT NULL,<br/>      <em>--snip--</em><br/>      wifisess integer NOT NULL,<br/>      yr_sub integer NOT NULL<br/>  );<br/><span class="ent">➋</span> CREATE INDEX libname2014_idx ON pls_fy2014_pupld14a (libname);<br/>  CREATE INDEX stabr2014_idx ON pls_fy2014_pupld14a (stabr);<br/>  CREATE INDEX city2014_idx ON pls_fy2014_pupld14a (city);<br/>  CREATE INDEX visits2014_idx ON pls_fy2014_pupld14a (visits);<br/><br/><span class="ent">➌</span> COPY pls_fy2014_pupld14a<br/>  FROM '<em>C:\YourDirectory\</em>pls_fy2014_pupld14a.csv'<br/>  WITH (FORMAT CSV, HEADER);</p>
<p class="listing" id="ch08list1"><em>Listing 8-1: Creating and filling the 2014 Public Libraries Survey table</em></p>
<p class="indent">After finding the code and data file for <a href="ch08.xhtml#ch08list1">Listing 8-1</a>, connect to your <span class="literal">analysis</span> database in pgAdmin and run it. Remember to change <em><span class="literal">C:\YourDirectory\</span></em> to the path where you saved the CSV file.</p>
<p class="indent">Here’s what it does: first, the code makes the table via <span class="literal">CREATE TABLE</span>. We assign a primary key constraint to the column named <span class="literal">fscskey</span> <span class="ent">➊</span>, a unique code the data dictionary says is assigned to each library. Because it’s unique, present in each row, and unlikely to change, it can serve as a natural primary key.</p>
<p class="indent">The definition for each column includes the appropriate data type and <span class="literal">NOT NULL</span> constraints where the columns have no missing values. If you look carefully in the data dictionary, you’ll notice that I changed the column named <span class="literal">database</span> in the CSV file to <span class="literal">databases</span> in the table. The reason is that <span class="literal">database</span> is a SQL reserved keyword, and it’s unwise to use keywords as identifiers because it can lead to unintended consequences in queries or other functions.</p>
<p class="indent">The <span class="literal">startdat</span> and <span class="literal">enddat</span> columns contain dates, but we’ve set their data type to <span class="literal">varchar(10)</span> in the code because in the CSV file those columns include non-date values, and our import will fail if we try to use a <span class="literal">date</span> data type. In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll learn how to clean up cases like these. For now, those columns are fine as is.</p>
<p class="indent"><span epub:type="pagebreak" id="page_116"/>After creating the table, we add indexes <span class="ent">➋</span> to columns we’ll use for queries. This provides faster results when we search the column for a particular library. The <span class="literal">COPY</span> statement <span class="ent">➌</span> imports the data from a CSV file named <em>pls_fy2014_pupld14a.csv</em> using the file path you provide.</p>
<h4 class="h4" id="lev122"><em>Creating the 2009 Library Data Table</em></h4>
<p class="noindent">Creating the table for the 2009 library data follows similar steps, as shown in <a href="ch08.xhtml#ch08list2">Listing 8-2</a>. Most ongoing surveys will have a handful of year-to-year changes because the makers of the survey either think of new questions or modify existing ones, so the included columns will be slightly different in this table. That’s one reason the data providers create new tables instead of adding rows to a cumulative table. For example, the 2014 file has a <span class="literal">wifisess</span> column, which lists the annual number of Wi-Fi sessions the library provided, but this column doesn’t exist in the 2009 data. The data dictionary for this survey year is at <em><a href="https://www.imls.gov/sites/default/files/fy2009_pls_data_file_documentation.pdf">https://www.imls.gov/sites/default/files/fy2009_pls_data_file_documentation.pdf</a></em>.</p>
<p class="indent">After you build this table, import the CSV file <em>pls_fy2009_pupld09a</em>. This file is also available to download along with all the book’s resources at <em><a href="https://www.nostarch.com/practicalSQL/">https://www.nostarch.com/practicalSQL/</a></em>. When you’ve saved the file and added the correct file path to the <span class="literal">COPY</span> statement, execute the code in <a href="ch08.xhtml#ch08list2">Listing 8-2</a>:</p>
<p class="programs"><br/>  CREATE TABLE pls_fy2009_pupld09a (<br/>      stabr varchar(2) NOT NULL,<br/>    <span class="ent">➊</span> fscskey varchar(6) CONSTRAINT fscskey2009_key PRIMARY KEY,<br/>      libid varchar(20) NOT NULL,<br/>      libname varchar(100) NOT NULL,<br/>      address varchar(35) NOT NULL,<br/>      city varchar(20) NOT NULL,<br/>      zip varchar(5) NOT NULL,<br/>      zip4 varchar(4) NOT NULL,<br/>      cnty varchar(20) NOT NULL,<br/>      <em>--snip--</em><br/>      fipsst varchar(2) NOT NULL,<br/>      fipsco varchar(3) NOT NULL<br/>  );<br/><span class="ent">➋</span> CREATE INDEX libname2009_idx ON pls_fy2009_pupld09a (libname);<br/>  CREATE INDEX stabr2009_idx ON pls_fy2009_pupld09a (stabr);<br/>  CREATE INDEX city2009_idx ON pls_fy2009_pupld09a (city);<br/>  CREATE INDEX visits2009_idx ON pls_fy2009_pupld09a (visits);<br/><br/>  COPY pls_fy2009_pupld09a<br/>  FROM '<em>C:\YourDirectory\</em>pls_fy2009_pupld09a.csv'<br/>  WITH (FORMAT CSV, HEADER);</p>
<p class="listing" id="ch08list2"><em>Listing 8-2: Creating and filling the 2009 Public Libraries Survey table</em></p>
<p class="indent">We use <span class="literal">fscskey</span> as the primary key again <span class="ent">➊</span>, and we create an index on <span class="literal">libname</span> and other columns <span class="ent">➋</span>. Now, let’s mine the two tables of library data from 2014 and 2009 to discover their stories.</p>
<h3 class="h3" id="lev123"><span epub:type="pagebreak" id="page_117"/><strong>Exploring the Library Data Using Aggregate Functions</strong></h3>
<p class="noindent">Aggregate functions combine values from multiple rows and return a single result based on an operation on those values. For example, you might return the average of values with the <span class="literal">avg()</span> function, as you learned in <a href="ch05.xhtml#ch05">Chapter 5</a>. That’s just one of many aggregate functions in SQL. Some are part of the SQL standard, and others are specific to PostgreSQL and other database managers. Most of the aggregate functions used in this chapter are part of standard SQL (a full list of PostgreSQL aggregates is at <em><a href="https://www.postgresql.org/docs/current/static/functions-aggregate.html">https://www.postgresql.org/docs/current/static/functions-aggregate.html</a></em>).</p>
<p class="indent">In this section, we’ll work through the library data using aggregates on single and multiple columns, and then explore how you can expand their use by grouping the results they return with values from additional columns.</p>
<h4 class="h4" id="lev124"><em>Counting Rows and Values Using count()</em></h4>
<p class="noindent">After importing a data set, a sensible first step is to make sure the table has the expected number of rows. For example, the IMLS documentation for the 2014 data says the file we imported has 9,305 rows, and the 2009 file has 9,299 rows. When we count the number of rows in those tables, the results should match those counts.</p>
<p class="indent">The <span class="literal">count()</span> aggregate function, which is part of the ANSI SQL standard, makes it easy to check the number of rows and perform other counting tasks. If we supply an asterisk as an input, such as <span class="literal">count(*)</span>, the asterisk acts as a wildcard, so the function returns the number of table rows regardless of whether they include <span class="literal">NULL</span> values. We do this in both statements in <a href="ch08.xhtml#ch08list3">Listing 8-3</a>:</p>
<p class="programs">SELECT count(*)<br/>FROM pls_fy2014_pupld14a;<br/><br/>SELECT count(*)<br/>FROM pls_fy2009_pupld09a;</p>
<p class="listing" id="ch08list3"><em>Listing 8-3: Using <span class="literal">count()</span> for table row counts</em></p>
<p class="indent">Run each of the commands in <a href="ch08.xhtml#ch08list3">Listing 8-3</a> one at a time to see the table row counts. For <span class="literal">pls_fy2014_pupld14a</span>, the result should be:</p>
<p class="programs">count<br/>-----<br/> 9305</p>
<p class="indent">And for <span class="literal">pls_fy2009_pupld09a</span>, the result should be:</p>
<p class="programs">count<br/>-----<br/> 9299</p>
<p class="indent">Both results match the number of rows we expected.</p>
<div class="note">
<p class="notet"><span epub:type="pagebreak" id="page_118"/><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>You can also check the row count using the pgAdmin interface, but it’s clunky. Right-clicking the table name in pgAdmin’s object browser and selecting <strong>View/Edit Data</strong></em> <span class="ent">▸</span> <em><strong>All Rows</strong> executes a SQL query for all rows. Then, a pop-up message in the results pane shows the row count, but it disappears after a few seconds.</em></p>
</div>
<p class="indent">Comparing the number of table rows to what the documentation says is important because it will alert us to issues such as missing rows or cases where we might have imported the wrong file.</p>
<h5 class="h5" id="lev125">Counting Values Present in a Column</h5>
<p class="noindent">To return the number of rows in a specific column that contain values, we supply the name of a column as input to the <span class="literal">count()</span> function rather than an asterisk. For example, if you scan the <span class="literal">CREATE TABLE</span> statements for both library tables closely, you’ll notice that we omitted the <span class="literal">NOT NULL</span> constraint for the <span class="literal">salaries</span> column plus several others. The reason is that not every library agency reported salaries, and some rows have <span class="literal">NULL</span> values.</p>
<p class="indent">To count the number of rows in the salaries column from 2014 that have values, run the <span class="literal">count()</span> function in <a href="ch08.xhtml#ch08list4">Listing 8-4</a>:</p>
<p class="programs">SELECT count(salaries)<br/>FROM pls_fy2014_pupld14a;</p>
<p class="listing" id="ch08list4"><em>Listing 8-4: Using <span class="literal">count()</span> for the number of values in a column</em></p>
<p class="indent">The result shows 5,983 rows have a value in <span class="literal">salaries</span>:</p>
<p class="programs">count<br/>-----<br/> 5983</p>
<p class="indent">This number is far lower than the number of rows that exist in the table. In the 2014 data, slightly less than two-thirds of the agencies reported salaries, and you’d want to note that fact when reporting any results of calculations performed on those columns. This check is important because the extent to which values are present in a column might influence your decision on whether to proceed with analysis at all. Checking with experts on the topic and digging deeper into the data is usually a good idea, and I recommend seeking expert advice as part of a broader analysis methodology (for more on this topic, see <a href="ch18.xhtml#ch18">Chapter 18</a>).</p>
<h5 class="h5" id="lev126">Counting Distinct Values in a Column</h5>
<p class="noindent">In <a href="ch02.xhtml#ch02">Chapter 2</a>, I covered the <span class="literal">DISTINCT</span> keyword, which is part of the SQL standard. When added after <span class="literal">SELECT</span> in a query, <span class="literal">DISTINCT</span> returns a list of unique values. We can use it to see unique values in one column, or we can see unique combinations of values from multiple columns. Another use of <span class="literal">DISTINCT</span> is to add it to the <span class="literal">count()</span> function, which causes the function to return a count of distinct values from a column.</p>
<p class="indent"><span epub:type="pagebreak" id="page_119"/><a href="ch08.xhtml#ch08list5">Listing 8-5</a> shows two queries. The first counts all values in the 2014 table’s <span class="literal">libname</span> column. The second does the same but includes <span class="literal">DISTINCT</span> in front of the column name. Run them both, one at a time.</p>
<p class="programs">SELECT count(libname)<br/>FROM pls_fy2014_pupld14a;<br/><br/>SELECT count(DISTINCT libname)<br/>FROM pls_fy2014_pupld14a;</p>
<p class="listing" id="ch08list5"><em>Listing 8-5: Using <span class="literal">count()</span> for the number of distinct values in a column</em></p>
<p class="indent">The first query returns a row count that matches the number of rows in the table that we found using <a href="ch08.xhtml#ch08list3">Listing 8-3</a>:</p>
<p class="programs">count<br/>-----<br/> 9305</p>
<p class="indent">That’s good. We expect to have the library agency name listed in every row. But the second query returns a smaller number:</p>
<p class="programs">count<br/>-----<br/> 8515</p>
<p class="indent">Using <span class="literal">DISTINCT</span> to remove duplicates reduces the number of library names to the 8,515 that are unique. My closer inspection of the data shows that 530 library agencies share their name with one or more other agencies. As one example, nine library agencies are named <span class="literal">OXFORD PUBLIC LIBRARY</span> in the table, each one in a city or town named Oxford in different states, including Alabama, Connecticut, Kansas, and Pennsylvania, among others. We’ll write a query to see combinations of distinct values in <a href="ch08.xhtml#lev128">“Aggregating Data Using <span class="literal">GROUP BY</span>”</a> on <a href="ch08.xhtml#page_120">page 120</a>.</p>
<h4 class="h4" id="lev127"><em>Finding Maximum and Minimum Values Using max() and min()</em></h4>
<p class="noindent">Knowing the largest and smallest numbers in a column is useful for a couple of reasons. First, it helps us get a sense of the scope of the values reported for a particular variable. Second, the functions used, <span class="literal">max()</span> and <span class="literal">min()</span>, can reveal unexpected issues with the data, as you’ll see now with the libraries data.</p>
<p class="indent">Both <span class="literal">max()</span> and <span class="literal">min()</span> work the same way: you use a <span class="literal">SELECT</span> statement followed by the function with the name of a column supplied. <a href="ch08.xhtml#ch08list6">Listing 8-6</a> uses <span class="literal">max()</span> and <span class="literal">min()</span> on the 2014 table with the <span class="literal">visits</span> column as input. The <span class="literal">visits</span> column records the number of annual visits to the library agency and all of its branches. Run the code, and then we’ll review the output.</p>
<p class="programs">SELECT max(visits), min(visits)<br/>FROM pls_fy2014_pupld14a;</p>
<p class="listing" id="ch08list6"><em>Listing 8-6: Finding the most and fewest visits using <span class="literal">max()</span> and <span class="literal">min()</span></em></p>
<p class="indent"><span epub:type="pagebreak" id="page_120"/>The query returns the following results:</p>
<p class="programs">max         min<br/>--------    ---<br/>17729020     -3</p>
<p class="indent">Well, that’s interesting. The maximum value of more than 17.7 million is reasonable for a large city library system, but <span class="literal">-3</span> as the minimum? On the surface, that result seems like a mistake, but it turns out that the creators of the library survey are employing a problematic yet common convention in data collection: using a negative number or some artificially high value as an indicator.</p>
<p class="indent">In this case, the survey creators used negative numbers to indicate the following conditions:</p>
<ol>
<li class="noindent"><p class="list">A value of <span class="literal">-1</span> indicates a “nonresponse” to that question.</p></li>
<li class="noindent"><p class="list">A value of <span class="literal">-3</span> indicates “not applicable” and is used when a library agency has closed either temporarily or permanently.</p></li>
</ol>
<p class="indent">We’ll need to account for and exclude negative values as we explore the data, because summing a column and including the negative values will result in an incorrect total. We can do this using a <span class="literal">WHERE</span> clause to filter them. It’s a good thing we discovered this issue now rather than later after spending a lot of time on deeper analysis!</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>A better alternative for this negative value scenario is to use <em><span class="literal">NULL</span> in rows in the <span class="literal">visits</span></em> column where response data is absent, and then create a separate <span class="codeitalic">visits_flag</span> column to hold codes explaining why. This technique separates number values from information about them.</em></p>
</div>
<h4 class="h4" id="lev128"><em>Aggregating Data Using GROUP BY</em></h4>
<p class="noindent">When you use the <span class="literal">GROUP BY</span> clause with aggregate functions, you can group results according to the values in one or more columns. This allows us to perform operations like <span class="literal">sum()</span> or <span class="literal">count()</span> for every state in our table or for every type of library agency.</p>
<p class="indent">Let’s explore how using <span class="literal">GROUP BY</span> with aggregates works. On its own, <span class="literal">GROUP BY</span>, which is also part of standard ANSI SQL, eliminates duplicate values from the results, similar to <span class="literal">DISTINCT</span>. <a href="ch08.xhtml#ch08list7">Listing 8-7</a> shows the <span class="literal">GROUP BY</span> clause in action:</p>
<p class="programs">  SELECT stabr<br/>  FROM pls_fy2014_pupld14a<br/><span class="ent">➊</span> GROUP BY stabr<br/>  ORDER BY stabr;</p>
<p class="listing" id="ch08list7"><em>Listing 8-7: Using <span class="literal">GROUP BY</span> on the <span class="literal">stabr</span> column</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_121"/>The <span class="literal">GROUP BY</span> clause <span class="ent">➊</span> follows the <span class="literal">FROM</span> clause and includes the column name to group. In this case, we’re selecting <span class="literal">stabr</span>, which contains the state abbreviation, and grouping by that same column. We then use <span class="literal">ORDER BY</span> <span class="literal">stabr</span> as well so that the grouped results are in alphabetical order. This will yield a result with unique state abbreviations from the 2014 table. Here’s a portion of the results:</p>
<p class="programs">stabr<br/>-----<br/>AK<br/>AL<br/>AR<br/>AS<br/>AZ<br/>CA<br/><em>--snip--</em><br/>WV<br/>WY</p>
<p class="indent">Notice that there are no duplicates in the 56 rows returned. These standard two-letter postal abbreviations include the 50 states plus Washington, D.C., and several U.S. territories, such as American Samoa and the U.S. Virgin Islands.</p>
<p class="indent">You’re not limited to grouping just one column. In <a href="ch08.xhtml#ch08list8">Listing 8-8</a>, we use the <span class="literal">GROUP BY</span> clause on the 2014 data to specify the <span class="literal">city</span> and <span class="literal">stabr</span> columns for grouping:</p>
<p class="programs">SELECT city, stabr<br/>FROM pls_fy2014_pupld14a<br/>GROUP BY city, stabr<br/>ORDER BY city, stabr;</p>
<p class="listing" id="ch08list8"><em>Listing 8-8: Using <span class="literal">GROUP BY</span> on the <span class="literal">city</span> and <span class="literal">stabr</span> columns</em></p>
<p class="indent">The results get sorted by city and then by state, and the output shows unique combinations in that order:</p>
<p class="programs">city          stabr<br/>----------    -----<br/>ABBEVILLE     AL<br/>ABBEVILLE     LA<br/>ABBEVILLE     SC<br/>ABBOTSFORD    WI<br/>ABERDEEN      ID<br/>ABERDEEN      SD<br/>ABERNATHY     TX<br/><em>--snip--</em></p>
<p class="indent">This grouping returns 9,088 rows, 217 fewer than the total table rows. The result indicates there are multiple occasions where the file includes more than one library agency for a particular city and state combination.</p>
<h5 class="h5" id="lev129"><span epub:type="pagebreak" id="page_122"/>Combining GROUP BY with count()</h5>
<p class="noindent">If we combine <span class="literal">GROUP BY</span> with an aggregate function, such as <span class="literal">count()</span>, we can pull more descriptive information from our data. For example, we know 9,305 library agencies are in the 2014 table. We can get a count of agencies by state and sort them to see which states have the most. <a href="ch08.xhtml#ch08list9">Listing 8-9</a> shows how:</p>
<p class="programs"><span class="ent">➊</span> SELECT stabr, count(*)<br/>  FROM pls_fy2014_pupld14a<br/><span class="ent">➋</span> GROUP BY stabr<br/><span class="ent">➌</span> ORDER BY count(*) DESC;</p>
<p class="listing" id="ch08list9"><em>Listing 8-9: Using <span class="literal">GROUP BY</span> with <span class="literal">count()</span> on the <span class="literal">stabr</span> column</em></p>
<p class="indent">Unlike in earlier examples, we’re now asking for the values in the <span class="literal">stabr</span> column and a count of those values. In the list of columns to query <span class="ent">➊</span>, we specify <span class="literal">stabr</span> and the <span class="literal">count()</span> function with an asterisk as its input. As before, the asterisk causes <span class="literal">count()</span> to include <span class="literal">NULL</span> values. Also, when we select individual columns along with an aggregate function, we must include the columns in a <span class="literal">GROUP BY</span> clause <span class="ent">➋</span>. If we don’t, the database will return an error telling us to do so. The reason is that you can’t group values by aggregating and have ungrouped column values in the same query.</p>
<p class="indent">To sort the results and have the state with the largest number of agencies at the top, we can <span class="literal">ORDER BY</span> the <span class="literal">count()</span> function <span class="ent">➌</span> in descending order using <span class="literal">DESC</span>.</p>
<p class="indent">Run the code in <a href="ch08.xhtml#ch08list9">Listing 8-9</a>. The results show New York, Illinois, and Texas as the states with the greatest number of library agencies in 2014:</p>
<p class="programs">stabr    count<br/>-----    -----<br/>NY         756<br/>IL         625<br/>TX         556<br/>IA         543<br/>PA         455<br/>MI         389<br/>WI         381<br/>MA         370<br/><em>--snip--</em></p>
<p class="indent">Remember that our table represents library agencies that serve a locality. Just because New York, Illinois, and Texas have the greatest number of library agencies doesn’t mean they have the greatest number of outlets where you can walk in and peruse the shelves. An agency might have one central library only, or it might have no central libraries but 23 branches spread around a county. To count outlets, each row in the table also has values in the columns <span class="literal">centlib</span> and <span class="literal">branlib</span>, which record the number of central and branch libraries, respectively. To find totals, we would use the <span class="literal">sum()</span> aggregate function on both columns.</p>
<h5 class="h5" id="lev130"><span epub:type="pagebreak" id="page_123"/>Using GROUP BY on Multiple Columns with count()</h5>
<p class="noindent">We can glean yet more information from our data by combining <span class="literal">GROUP BY</span> with the <span class="literal">count()</span> function and multiple columns. For example, the <span class="literal">stataddr</span> column in both tables contains a code indicating whether the agency’s address changed in the last year. The values in <span class="literal">stataddr</span> are:</p>
<p class="hang"><strong>00</strong> No change from last year</p>
<p class="hang"><strong>07</strong> Moved to a new location</p>
<p class="hang"><strong>15</strong> Minor address change</p>
<p class="indentt"><a href="ch08.xhtml#ch08list10">Listing 8-10</a> shows the code for counting the number of agencies in each state that moved, had a minor address change, or had no change using <span class="literal">GROUP BY</span> with <span class="literal">stabr</span> and <span class="literal">stataddr</span> and adding <span class="literal">count()</span>:</p>
<p class="programs"><span class="ent">➊</span> SELECT stabr, stataddr, count(*)<br/>  FROM pls_fy2014_pupld14a<br/><span class="ent">➋</span> GROUP BY stabr, stataddr<br/><span class="ent">➌</span> ORDER BY stabr ASC, count(*) DESC;</p>
<p class="listing" id="ch08list10"><em>Listing 8-10: Using <span class="literal">GROUP BY</span> with <span class="literal">count()</span> of the <span class="literal">stabr</span> and <span class="literal">stataddr</span> columns</em></p>
<p class="indent">The key sections of the query are the column names and the <span class="literal">count()</span> function after <span class="literal">SELECT</span> <span class="ent">➊</span>, and making sure both columns are reflected in the <span class="literal">GROUP BY</span> clause <span class="ent">➋</span>. The effect of grouping by two columns is that <span class="literal">count()</span> will show the number of unique combinations of <span class="literal">stabr</span> and <span class="literal">stataddr</span>.</p>
<p class="indent">To make the output easier to read, let’s sort first by the state code in ascending order and then by the count in descending order <span class="ent">➌</span>. Here are the results:</p>
<p class="programs">stabr    stataddr    count<br/>-----    --------    -----<br/>AK       00             70<br/>AK       15             10<br/>AK       07              5<br/>AL       00            221<br/>AL       07              3<br/>AR       00             58<br/>AS       00              1<br/>AZ       00             91<br/><em>--snip--</em></p>
<p class="indent">The first few rows of the results show that code <span class="literal">00</span> (no change in address) is the most common value for each state. We’d expect that because it’s likely there are more library agencies that haven’t changed address than those that have. The result helps assure us that we’re analyzing the data in a sound way. If code <span class="literal">07</span> (moved to a new location) was the most frequent in each state, that would raise a question about whether we’ve written the query correctly or whether there’s an issue with the data.</p>
<h5 class="h5" id="lev131"><span epub:type="pagebreak" id="page_124"/>Revisiting sum() to Examine Library Visits</h5>
<p class="noindent">So far, we’ve combined grouping with aggregate functions, like <span class="literal">count()</span>, on columns within a single table to provide results grouped by a column’s values. Now let’s expand the technique to include grouping and aggregating across joined tables using the 2014 and 2009 libraries data. Our goal is to identify trends in library visits spanning that five-year period. To do this, we need to calculate totals using the <span class="literal">sum()</span> aggregate function.</p>
<p class="indent">Before we dig into these queries, let’s address the issue of using the values <span class="literal">-3</span> and <span class="literal">-1</span> to indicate “not applicable” and “nonresponse.” To prevent these negative numbers with no meaning as quantities from affecting the analysis, we’ll filter them out using a <span class="literal">WHERE</span> clause to limit the queries to rows where values in <span class="literal">visits</span> are zero or greater.</p>
<p class="indent">Let’s start by calculating the sum of annual visits to libraries from the individual 2014 and 2009 tables. Run each <span class="literal">SELECT</span> statement in <a href="ch08.xhtml#ch08list11">Listing 8-11</a> separately:</p>
<p class="programs">SELECT sum(visits) AS visits_2014<br/>FROM pls_fy2014_pupld14a<br/>WHERE visits &gt;= 0;<br/><br/>SELECT sum(visits) AS visits_2009<br/>FROM pls_fy2009_pupld09a<br/>WHERE visits &gt;= 0;</p>
<p class="listing" id="ch08list11"><em>Listing 8-11: Using the <span class="literal">sum()</span> aggregate function to total visits to libraries in 2014 and 2009</em></p>
<p class="indent">For 2014, visits totaled approximately 1.4 billion.</p>
<p class="programs">visits_2014<br/>-----------<br/> 1425930900</p>
<p class="indent">For 2009, visits totaled approximately 1.6 billion. We’re onto something here, but it may not be good news. The trend seems to point downward with visits dropping about 10 percent from 2009 to 2014.</p>
<p class="programs">visits_2009<br/>-----------<br/> 1591799201</p>
<p class="indent">These queries sum overall visits. But from the row counts we ran earlier in the chapter, we know that each table contains a different number of library agencies: 9,305 in 2014 and 9,299 in 2009 due to agencies opening, closing, or merging. So, let’s determine how the sum of visits will differ if we limit the analysis to library agencies that exist in both tables. We can do that by joining the tables, as shown in <a href="ch08.xhtml#ch08list12">Listing 8-12</a>:</p>
<p class="programs"><span class="ent">➊</span> SELECT sum(pls14.visits) AS visits_2014,<br/>         sum(pls09.visits) AS visits_2009<br/><span class="ent">➋</span> FROM pls_fy2014_pupld14a pls14 JOIN pls_fy2009_pupld09a pls09<br/><span epub:type="pagebreak" id="page_125"/>  ON pls14.fscskey = pls09.fscskey<br/><span class="ent">➌</span> WHERE pls14.visits &gt;= 0 AND pls09.visits &gt;= 0;</p>
<p class="listing" id="ch08list12"><em>Listing 8-12: Using the <span class="literal">sum()</span> aggregate function to total visits on joined 2014 and 2009 library tables</em></p>
<p class="indent">This query pulls together a few concepts we covered in earlier chapters, including table joins. At the top, we use the <span class="literal">sum()</span> aggregate function <span class="ent">➊</span> to total the <span class="literal">visits</span> columns from the 2014 and 2009 tables. When we join the tables on the tables’ primary keys, we’re declaring table aliases <span class="ent">➋</span> as we explored in <a href="ch06.xhtml#ch06">Chapter 6</a>. Here, we declare <span class="literal">pls14</span> as the alias for the 2014 table and <span class="literal">pls09</span> as the alias for the 2009 table to avoid having to write the lengthier full table names throughout the query.</p>
<p class="indent">Note that we use a standard <span class="literal">JOIN</span>, also known as an <span class="literal">INNER JOIN</span>. That means the query results will only include rows where the primary key values of both tables (the column <span class="literal">fscskey</span>) match.</p>
<p class="indent">Using the <span class="literal">WHERE</span> clause <span class="ent">➌</span>, we return rows where both tables have a value of zero or greater in the <span class="literal">visits</span> column. As we did in <a href="ch08.xhtml#ch08list11">Listing 8-11</a>, we specify that the result should include only those rows where <span class="literal">visits</span> are greater than or equal to 0 in both tables. This will prevent the artificial negative values from impacting the sums.</p>
<p class="indent">Run the query. The results should look like this:</p>
<p class="programs">
visits_2014    visits_2009<br/>-----------    -----------<br/> 1417299241     1585455205</p>
<p class="indent">The results are similar to what we found by querying the tables separately, although these totals are six to eight million smaller. The reason is that the query referenced only agencies with an <span class="literal">fscskey</span> in both tables. Still, the downward trend holds. We’ll need to dig a little deeper to get the full story.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Although we joined the tables on <span class="codeitalic">fscskey</span>, it’s entirely possible that some library agencies that appear in both tables merged or split between 2009 and 2014. A call to the IMLS asking about caveats for working with this data is a good idea.</em></p>
</div>
<h5 class="h5" id="lev132">Grouping Visit Sums by State</h5>
<p class="noindent">Now that we know library visits dropped for the United States as a whole between 2009 and 2014, you might ask yourself, “Did every part of the country see a decrease, or did the degree of the trend vary by region?” We can answer this question by modifying our preceding query to group by the state code. Let’s also use a percent-change calculation to compare the trend by state. <a href="ch08.xhtml#ch08list13">Listing 8-13</a> contains the full code:</p>
<p class="programs"><span class="ent">➊</span> SELECT pls14.stabr,<br/>         sum(pls14.visits) AS visits_2014,<br/>         sum(pls09.visits) AS visits_2009,<br/>         round( (CAST(sum(pls14.visits) AS decimal(10,1)) - sum(pls09.visits)) /<br/>                      sum(pls09.visits) * 100, 2 ) AS pct_change<span class="ent">➋</span><br/><span epub:type="pagebreak" id="page_126"/>  FROM pls_fy2014_pupld14a pls14 JOIN pls_fy2009_pupld09a pls09<br/>  ON pls14.fscskey = pls09.fscskey<br/>  WHERE pls14.visits &gt;= 0 AND pls09.visits &gt;= 0<br/><span class="ent">➌</span> GROUP BY pls14.stabr<br/><span class="ent">➍</span> ORDER BY pct_change DESC;</p>
<p class="listing" id="ch08list13"><em>Listing 8-13: Using <span class="literal">GROUP BY</span> to track percent change in library visits by state</em></p>
<p class="indent">We follow the <span class="literal">SELECT</span> keyword with the <span class="literal">stabr</span> column <span class="ent">➊</span> from the 2014 table; that same column appears in the <span class="literal">GROUP BY</span> clause <span class="ent">➌</span>. It doesn’t matter which table’s <span class="literal">stabr</span> column we use because we’re only querying agencies that appear in both tables. After <span class="literal">SELECT</span>, we also include the now-familiar percent-change calculation you learned in <a href="ch05.xhtml#ch05">Chapter 5</a>, which gets the alias <span class="literal">pct_change</span> <span class="ent">➋</span> for readability. We end the query with an <span class="literal">ORDER BY</span> clause <span class="ent">➍</span>, using the <span class="literal">pct_change</span> column alias.</p>
<p class="indent">When you run the query, the top of the results shows 10 states or territories with an increase in visits from 2009 to 2014. The rest of the results show a decline. Oklahoma, at the bottom of the ranking, had a 35 percent drop!</p>
<p class="programs">stabr    visits_2014    visits_2009    pct_change<br/>-----    -----------    -----------    ----------<br/>GU            103593          60763         70.49<br/>DC           4230790        2944774         43.67<br/>LA          17242110       15591805         10.58<br/>MT           4582604        4386504          4.47<br/>AL          17113602       16933967          1.06<br/>AR          10762521       10660058          0.96<br/>KY          19256394       19113478          0.75<br/>CO          32978245       32782247          0.60<br/>SC          18178677       18105931          0.40<br/>SD           3899554        3890392          0.24<br/>MA          42011647       42237888         -0.54<br/>AK           3486955        3525093         -1.08<br/>ID           8730670        8847034         -1.32<br/>NH           7508751        7675823         -2.18<br/>WY           3666825        3756294         -2.38<br/><em>--snip--</em><br/>RI           5259143        6612167        -20.46<br/>NC          33952977       43111094        -21.24<br/>PR            193279         257032        -24.80<br/>GA          28891017       40922598        -29.40<br/>OK          13678542       21171452        -35.39</p>
<p class="indent">This useful data should lead a data analyst to investigate what’s driving the changes, particularly the largest ones. Data analysis can sometimes raise as many questions as it answers, but that’s part of the process. It’s always worth a phone call to a person with knowledge about the data to provide context for the results. Sometimes, they may have a very good explanation. Other times, an expert will say, “That doesn’t sound right.” That answer might send you back to the keeper of the data or the documentation to find out if you overlooked a code or a nuance with the data.</p>
<h5 class="h5" id="lev133"><span epub:type="pagebreak" id="page_127"/>Filtering an Aggregate Query Using HAVING</h5>
<p class="noindent">We can refine our analysis by examining a subset of states and territories that share similar characteristics. With percent change in visits, it makes sense to separate large states from small states. In a small state like Rhode Island, one library closing could have a significant effect. A single closure in California might be scarcely noticed in a statewide count. To look at states with a similar volume in visits, we could sort the results by either of the <span class="literal">visits</span> columns, but it would be cleaner to get a smaller result set in our query.</p>
<p class="indent">To filter the results of aggregate functions, we need to use the <span class="literal">HAVING</span> clause that’s part of standard ANSI SQL. You’re already familiar with using <span class="literal">WHERE</span> for filtering, but aggregate functions, such as <span class="literal">sum()</span>, can’t be used within a <span class="literal">WHERE</span> clause because they operate at the row level, and aggregate functions work across rows. The <span class="literal">HAVING</span> clause places conditions on groups created by aggregating. The code in <a href="ch08.xhtml#ch08list14">Listing 8-14</a> modifies the query in <a href="ch08.xhtml#ch08list13">Listing 8-13</a> by inserting the <span class="literal">HAVING</span> clause after <span class="literal">GROUP BY</span>:</p>
<p class="programs">  SELECT pls14.stabr,<br/>         sum(pls14.visits) AS visits_2014,<br/>         sum(pls09.visits) AS visits_2009,<br/>         round( (CAST(sum(pls14.visits) AS decimal(10,1)) - sum(pls09.visits)) /<br/>                      sum(pls09.visits) * 100, 2 ) AS pct_change<br/>  FROM pls_fy2014_pupld14a pls14 JOIN pls_fy2009_pupld09a pls09<br/>  ON pls14.fscskey = pls09.fscskey<br/>  WHERE pls14.visits &gt;= 0 AND pls09.visits &gt;= 0<br/>  GROUP BY pls14.stabr<br/><span class="ent">➊</span> HAVING sum(pls14.visits) &gt; 50000000<br/>  ORDER BY pct_change DESC;</p>
<p class="listing" id="ch08list14"><em>Listing 8-14: Using a <span class="literal">HAVING</span> clause to filter the results of an aggregate query</em></p>
<p class="indent">In this case, we’ve set our query results to include only rows with a sum of visits in 2014 greater than 50 million. That’s an arbitrary value I chose to show only the very largest states. Adding the <span class="literal">HAVING</span> clause <span class="ent">➊</span> reduces the number of rows in the output to just six. In practice, you might experiment with various values. Here are the results:</p>
<p class="programs">stabr    visits_2014    visits_2009    pct_change<br/>-----    -----------    -----------    ----------<br/>TX          72876601       78838400         -7.56<br/>CA         162787836      182181408        -10.65<br/>OH          82495138       92402369        -10.72<br/>NY         106453546      119810969        -11.15<br/>IL          72598213       82438755        -11.94<br/>FL          73165352       87730886        -16.60</p>
<p class="indent">Each of the six states has experienced a decline in visits, but notice that the percent-change variation isn’t as wide as in the full set of states and territories. Depending on what we learn from library experts, looking at the states with the most activity as a group might be helpful in describing trends, as would looking at other groupings. Think of a sentence or bullet point you <span epub:type="pagebreak" id="page_128"/>might write that would say, “In the nation’s largest states, visits decreased between 8 percent and 17 percent between 2009 and 2014.” You could write similar sentences about medium-sized states and small states.</p>
<h3 class="h3" id="lev134">Wrapping Up</h3>
<p class="noindent">If this chapter has inspired you to visit your local library and check out a couple of books, ask a librarian whether their branch has seen a rise or drop in visits over the last few years. Chances are, you can guess the answer now. In this chapter, you learned how to use standard SQL techniques to summarize data in a table by grouping values and using a handful of aggregate functions. By joining data sets, you were able to identify some interesting five-year trends.</p>
<p class="indent">You also learned that data doesn’t always come perfectly packaged. The use of negative values in columns as an indicator rather than as an actual numeric value forced us to filter out those rows. Unfortunately, data sets offer those kinds of challenges more often than not. In the next chapter, you’ll learn techniques to clean up a data set that has a number of issues. In subsequent chapters, you’ll also discover more aggregate functions to help you find the stories in your data.</p>
<div class="sidebar" id="ch08sb1">
<p class="sidebart"><strong>TRY IT YOURSELF</strong></p>
<p class="spara">Put your grouping and aggregating skills to the test with these challenges:</p>
<ol>
<li class="noindent"><p class="list">We saw that library visits have declined recently in most places. But what is the pattern in the use of technology in libraries? Both the 2014 and 2009 library survey tables contain the columns <span class="literal">gpterms</span> (the number of internet-connected computers used by the public) and <span class="literal">pitusr</span> (uses of public internet computers per year). Modify the code in <a href="ch08.xhtml#ch08list13">Listing 8-13</a> to calculate the percent change in the sum of each column over time. Watch out for negative values!</p></li>
<li class="noindent"><p class="list">Both library survey tables contain a column called <span class="literal">obereg</span>, a two-digit Bureau of Economic Analysis Code that classifies each library agency according to a region of the United States, such as New England, Rocky Mountains, and so on. Just as we calculated the percent change in visits grouped by state, do the same to group percent changes in visits by U.S. region using <span class="literal">obereg</span>. Consult the survey documentation to find the meaning of each region code. For a bonus challenge, create a table with the <span class="literal">obereg</span> code as the primary key and the region name as text, and join it to the summary query to group by the region name rather than the code.</p></li>
<li class="noindent"><p class="list">Thinking back to the types of joins you learned in <a href="ch06.xhtml#ch06">Chapter 6</a>, which join type will show you all the rows in both tables, including those without a match? Write such a query and add an <span class="literal">IS NULL</span> filter in a <span class="literal">WHERE</span> clause to show agencies not included in one or the other table.</p></li>
</ol>
</div>
</body>
</html>