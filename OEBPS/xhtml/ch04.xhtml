<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ns="http://www.w3.org/2001/10/synthesis" lang="en-us" xml:lang="en-us">
<head>
<title>Practical SQL: A Beginner’s Guide to Storytelling with Data</title>
<link href="../styles/9781593278458.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:c3d53d4c-356a-4b39-bef0-591c04016b72" name="Adept.expected.resource"/>
</head>
<body>
<h2 class="h2" id="ch04"><span epub:type="pagebreak" id="page_39"/><strong><span class="big">4</span></strong><br/><strong>IMPORTING AND EXPORTING DATA</strong></h2>
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>
<p class="noindent">So far, you’ve learned how to add a handful of rows to a table using SQL <span class="literal">INSERT</span> statements. A row-by-row insert is useful for making quick test tables or adding a few rows to an existing table. But it’s more likely you’ll need to load hundreds, thousands, or even millions of rows, and no one wants to write separate <span class="literal">INSERT</span> statements in those situations. Fortunately, you don’t have to.</p>
<p class="indent">If your data exists in a <em>delimited</em> text file (with one table row per line of text and each column value separated by a comma or other character) PostgreSQL can import the data in bulk via its <span class="literal">COPY</span> command. This command is a PostgreSQL-specific implementation with options for including or excluding columns and handling various delimited text types.</p>
<p class="indent"><span epub:type="pagebreak" id="page_40"/>In the opposite direction, <span class="literal">COPY</span> will also <em>export</em> data from PostgreSQL tables or from the result of a query to a delimited text file. This technique is handy when you want to share data with colleagues or move it into another format, such as an Excel file.</p>
<p class="indent">I briefly touched on <span class="literal">COPY</span> for export in <a href="ch03.xhtml#lev31">“Characters”</a> on <a href="ch03.xhtml#page_24">page 24</a>, but in this chapter I’ll discuss import and export in more depth. For importing, I’ll start by introducing you to one of my favorite data sets: the Decennial U.S. Census population tally by county.</p>
<p class="indent">Three steps form the outline of most of the imports you’ll do:</p>
<ol>
<li class="noindent"><p class="list">Prep the source data in the form of a delimited text file.</p></li>
<li class="noindent"><p class="list">Create a table to store the data.</p></li>
<li class="noindent"><p class="list">Write a <span class="literal">COPY</span> script to perform the import.</p></li>
</ol>
<p class="indent">After the import is done, we’ll check the data and look at additional options for importing and exporting.</p>
<p class="indent">A delimited text file is the most common file format that’s portable across proprietary and open source systems, so we’ll focus on that file type. If you want to transfer data from another database program’s proprietary format directly to PostgreSQL, such as Microsoft Access or MySQL, you’ll need to use a third-party tool. Check the PostgreSQL wiki at <em><a href="https://wiki.postgresql.org/wiki/">https://wiki.postgresql.org/wiki/</a></em> and search for “Converting from other Databases to PostgreSQL” for a list of tools.</p>
<p class="indent">If you’re using SQL with another database manager, check the other database’s documentation for how it handles bulk imports. The MySQL database, for example, has a <span class="literal">LOAD DATA INFILE</span> statement, and Microsoft’s SQL Server has its own <span class="literal">BULK INSERT</span> command.</p>
<h3 class="h3" id="lev47">Working with Delimited Text Files</h3>
<p class="noindent">Many software applications store data in a unique format, and translating one data format to another is about as easy as a person trying to read the Cyrillic alphabet if they understand only English. Fortunately, most software can import from and export to a delimited text file, which is a common data format that serves as a middle ground.</p>
<p class="indent">A delimited text file contains rows of data, and each row represents one row in a table. In each row, a character separates, or delimits, each data column. I’ve seen all kinds of characters used as delimiters, from ampersands to pipes, but the comma is most commonly used; hence the name of a file type you’ll see often: <em>comma-separated values (CSV)</em>. The terms <em>CSV</em> and <em>comma-delimited</em> are interchangeable.</p>
<p class="indent">Here’s a typical data row you might see in a comma-delimited file:</p>
<p class="programs">John,Doe,123 Main St.,Hyde Park,NY,845-555-1212</p>
<p class="indent"><span epub:type="pagebreak" id="page_41"/>Notice that a comma separates each piece of data—first name, last name, street, town, state, and phone—without any spaces. The commas tell the software to treat each item as a separate column, either upon import or export. Simple enough.</p>
<h4 class="h4" id="lev48"><em>Quoting Columns that Contain Delimiters</em></h4>
<p class="noindent">Using commas as a column delimiter leads to a potential dilemma: what if the value in a column includes a comma? For example, sometimes people combine an apartment number with a street address, as in 123 Main St., Apartment 200. Unless the system for delimiting accounts for that extra comma, during import the line will appear to have an extra column and cause the import to fail.</p>
<p class="indent">To handle such cases, delimited files wrap columns that contain a delimiter character with an arbitrary character called a <em>text qualifier</em> that tells SQL to ignore the delimiter character held within. Most of the time in comma-delimited files the text qualifier used is the double quote. Here’s the example data row again, but with the street name surrounded by double quotes:</p>
<p class="programs">John,Doe,"123 Main St., Apartment 200",Hyde Park,NY,845-555-1212</p>
<p class="indent">On import, the database will recognize that double quotes signify one column regardless of whether it finds a delimiter within the quotes. When importing CSV files, PostgreSQL by default ignores delimiters inside double-quoted columns, but you can specify a different text qualifier if your import requires it. (And, given the sometimes odd choices made by IT professionals, you may indeed need to employ a different character.)</p>
<h4 class="h4" id="lev49"><em>Handling Header Rows</em></h4>
<p class="noindent">Another feature you’ll often find inside a delimited text file is the <em>header row</em>. As the name implies, it’s a single row at the top, or head, of the file that lists the name of each data field. Usually, a header is created during the export of data from a database. Here’s an example with the delimited row I’ve been using:</p>
<p class="programs">FIRSTNAME,LASTNAME,STREET,CITY,STATE,PHONE<br/>John,Doe,"123 Main St., Apartment 200",Hyde Park,NY,845-555-1212</p>
<p class="indent">Header rows serve a few purposes. For one, the values in the header row identify the data in each column, which is particularly useful when you’re deciphering a file’s contents. Second, some database managers (although not PostgreSQL) use the header row to map columns in the delimited file to the correct columns in the import table. Because PostgreSQL doesn’t use the header row, we don’t want that row imported to a table, so we’ll use a <span class="literal">HEADER</span> option in the <span class="literal">COPY</span> command to exclude it. I’ll cover this with all <span class="literal">COPY</span> options in the next section.</p>
<h3 class="h3" id="lev50"><span epub:type="pagebreak" id="page_42"/>Using COPY to Import Data</h3>
<p class="noindent">To import data from an external file into our database, first we need to check out a source CSV file and build the table in PostgreSQL to hold the data. Thereafter, the SQL statement for the import is relatively simple. All you need are the three lines of code in <a href="ch04.xhtml#ch04list1">Listing 4-1</a>:</p>
<p class="programs"><span class="ent">➊</span> COPY <em>table_name</em><br/><span class="ent">➋</span> FROM '<em>C:\YourDirectory\your_file.csv</em>'<br/><span class="ent">➌</span> WITH (FORMAT CSV, HEADER);</p>
<p class="listing" id="ch04list1"><em>Listing 4-1: Using <span class="literal">COPY</span> for data import</em></p>
<p class="indent">The block of code starts with the <span class="literal">COPY</span> keyword <span class="ent">➊</span> followed by the name of the target table, which must already exist in your database. Think of this syntax as meaning, “Copy data to my table called <span class="codeitalic">table_name</span>.”</p>
<p class="indent">The <span class="literal">FROM</span> keyword <span class="ent">➋</span> identifies the full path to the source file, including its name. The way you designate the path depends on your operating system. For Windows, begin with the drive letter, colon, backslash, and directory names. For example, to import a file located on my Windows desktop, the <span class="literal">FROM</span> line would read:</p>
<p class="programs">FROM 'C:\Users\Anthony\Desktop\<em>my_file.csv</em>'</p>
<p class="indent">On macOS or Linux, start at the system root directory with a forward slash and proceed from there. Here’s what the <span class="literal">FROM</span> line might look like when importing a file located on my Mac desktop:</p>
<p class="programs">FROM '/Users/anthony/Desktop/<em>my_file.csv</em>'</p>
<p class="indent">Note that in both cases the full path and filename are surrounded by single quotes. For the examples in the book, I use the Windows-style path <span class="codeitalic">C:\YourDirectory\</span> as a placeholder. Replace that with the path where you stored the file.</p>
<p class="indent">The <span class="literal">WITH</span> keyword <span class="ent">➌</span> lets you specify options, surrounded by paren­theses, that you can tailor to your input or output file. Here we specify that the external file should be comma-delimited, and that we should exclude the file’s header row in the import. It’s worth examining all the options in the official PostgreSQL documentation at <em><a href="https://www.postgresql.org/docs/current/static/sql-copy.html">https://www.postgresql.org/docs/current/static/sql-copy.html</a></em>, but here is a list of the options you’ll commonly use:</p>
<p class="noindentt"><strong>Input and output file format</strong></p>
<p class="noindent1">Use the <span class="literal">FORMAT</span> <span class="codeitalic">format_name</span> option to specify the type of file you’re reading or writing. Format names are <span class="literal">CSV</span>, <span class="literal">TEXT</span>, or <span class="literal">BINARY</span>. Unless you’re deep into building technical systems, you’ll rarely encounter a need to work with <span class="literal">BINARY</span>, where data is stored as a sequence of bytes. More often, you’ll work with standard CSV files. In the <span class="literal">TEXT</span> format, a <em>tab</em> character <span epub:type="pagebreak" id="page_43"/>is the delimiter by default (although you can specify another character) and backslash characters such as <span class="literal">\r</span> are recognized as their ASCII equivalents—in this case, a carriage return. The <span class="literal">TEXT</span> format is used mainly by PostgreSQL’s built-in backup programs.</p>
<p class="noindentt"><strong>Presence of a header row</strong></p>
<p class="noindent1">On import, use <span class="literal">HEADER</span> to specify that the source file has a header row. You can also specify it longhand as <span class="literal">HEADER ON</span>, which tells the database to start importing with the second line of the file, preventing the unwanted import of the header. You don’t want the column names in the header to become part of the data in the table. On export, using <span class="literal">HEADER</span> tells the database to include the column names as a header row in the output file, which is usually helpful to do.</p>
<p class="noindentt"><strong>Delimiter</strong></p>
<p class="noindent1">The <span class="literal">DELIMITER</span> <span class="literal">'</span><span class="codeitalic">character</span><span class="literal">'</span> option lets you specify which character your import or export file uses as a delimiter. The delimiter must be a single character and cannot be a carriage return. If you use <span class="literal">FORMAT CSV</span>, the assumed delimiter is a comma. I include <span class="literal">DELIMITER</span> here to show that you have the option to specify a different delimiter if that’s how your data arrived. For example, if you received pipe-delimited data, you would treat the option this way: <span class="literal">DELIMITER '|'</span>.</p>
<p class="noindentt"><strong>Quote character</strong></p>
<p class="noindent1">Earlier, you learned that in a CSV, commas inside a single column value will mess up your import unless the column value is surrounded by a character that serves as a text qualifier, telling the database to handle the value within as one column. By default, PostgreSQL uses the double quote, but if the CSV you’re importing uses a different character, you can specify it with the <span class="literal">QUOTE</span> <span class="literal">'</span><span class="codeitalic">quote_character</span><span class="literal">'</span> option.</p>
<p class="indentt">Now that you better understand delimited files, you’re ready to import one.</p>
<h3 class="h3" id="lev51">Importing Census Data Describing Counties</h3>
<p class="noindent">The data set you’ll work with in this import exercise is considerably larger than the <span class="literal">teachers</span> table you made in <a href="ch01.xhtml#ch01">Chapter 1</a>. It contains census data about every county in the United States and is 3,143 rows deep and 91 columns wide.</p>
<p class="indent">To understand the data, it helps to know a little about the U.S. Census. Every 10 years, the government conducts a full count of the population—one of several ongoing programs by the Census Bureau to collect demographic data. Each household in America receives a questionnaire about each person in it—their age, gender, race, and whether they are Hispanic or not. The U.S. Constitution mandates the count to determine how many <span epub:type="pagebreak" id="page_44"/>members from each state make up the U.S. House of Representatives. Based on the 2010 Census, for example, Texas gained four seats in the House while New York and Ohio lost two seats each. Although apportioning House seats is the count’s main purpose, the data’s also a boon for trend trackers studying the population. A good synopsis of the 2010 count’s findings is available at <em><a href="https://www.census.gov/prod/cen2010/briefs/c2010br-01.pdf">https://www.census.gov/prod/cen2010/briefs/c2010br-01.pdf</a></em>.</p>
<p class="indent">The Census Bureau reports overall population totals and counts by race and ethnicity for various geographies including states, counties, cities, places, and school districts. For this exercise, I compiled a select collection of columns for the 2010 Census county-level counts into a file named <em>us_counties_2010.csv</em>. Download the <em>us_counties_2010.csv</em> file from <em><a href="https://www.nostarch.com/practicalSQL/">https://www.nostarch.com/practicalSQL/</a></em> and save it to a folder on your computer.</p>
<p class="indent">Open the file with a plain text editor. You should see a header row that begins with these columns:</p>
<p class="programs">NAME,STUSAB,SUMLEV,REGION,DIVISION,STATE,COUNTY <em>--snip--</em></p>
<p class="indent">Let’s explore some of the columns by examining the code for creating the import table.</p>
<h4 class="h4" id="lev52"><em>Creating the us_counties_2010 Table</em></h4>
<p class="noindent">The code in <a href="ch04.xhtml#ch04list2">Listing 4-2</a> shows only an abbreviated version of the <span class="literal">CREATE TABLE</span> script; many of the columns have been omitted. The full version is available (and annotated) along with all the code examples in the book’s resources. To import it properly, you’ll need to download the full table definition.</p>
<p class="programs">CREATE TABLE us_counties_2010 (<br/>  <span class="ent">➊</span> geo_name varchar(90),<br/>  <span class="ent">➋</span> state_us_abbreviation varchar(2),<br/>  <span class="ent">➌</span> summary_level varchar(3),<br/>  <span class="ent">➍</span> region smallint,<br/>    division smallint,<br/>    state_fips varchar(2),<br/>    county_fips varchar(3),<br/>  <span class="ent">➎</span> area_land bigint, <br/>    area_water bigint,<br/>  <span class="ent">➏</span> population_count_100_percent integer,<br/>    housing_unit_count_100_percent integer,<br/>  <span class="ent">➐</span> internal_point_lat numeric(10,7),<br/>    internal_point_lon numeric(10,7),<br/>  <span class="ent">➑</span> p0010001 integer,<br/>    p0010002 integer,<br/>    p0010003 integer,<br/>    p0010004 integer,<br/>    p0010005 integer,<br/>    <em>--snip--</em><br/>    p0040049 integer,<br/>    p0040065 integer,<br/><span epub:type="pagebreak" id="page_45"/>    p0040072 integer,<br/>    h0010001 integer,<br/>    h0010002 integer,<br/>    h0010003 integer<br/>);</p>
<p class="listing" id="ch04list2"><em>Listing 4-2: A <span class="literal">CREATE TABLE</span> statement for census county data</em></p>
<p class="indent">To create the table, in pgAdmin click the <span class="literal">analysis</span> database that you created in <a href="ch01.xhtml#ch01">Chapter 1</a>. (It’s best to store the data in this book in <span class="literal">analysis</span> because we’ll reuse some of it in later chapters.) From the pgAdmin menu bar, select <strong>Tools <span class="ent">▸</span> Query Tool</strong>. Paste the script into the window and run it.</p>
<p class="indent">Return to the main pgAdmin window, and in the object browser, right-click and refresh the <span class="literal">analysis</span> database. Choose <strong>Schemas <span class="ent">▸</span> public <span class="ent">▸</span> Tables</strong> to see the new table. Although it’s empty, you can see the structure by running a basic <span class="literal">SELECT</span> query in pgAdmin’s Query Tool:</p>
<p class="programs">SELECT * from us_counties_2010;</p>
<p class="indent">When you run the <span class="literal">SELECT</span> query, you’ll see the columns in the table you created. No data rows exist yet.</p>
<h4 class="h4" id="lev53"><em>Census Columns and Data Types</em></h4>
<p class="noindent">Before we import the CSV file into the table, let’s walk through several of the columns and the data types I chose in <a href="ch04.xhtml#ch04list2">Listing 4-2</a>. As my guide, I used the official census data dictionary for this data set found at <em><a href="http://www.census.gov/prod/cen2010/doc/pl94-171.pdf">http://www.census.gov/prod/cen2010/doc/pl94-171.pdf</a></em>, although I give some columns more readable names in the table definition. Relying on a data dictionary when possible is good practice, because it helps you avoid misconfiguring columns or potentially losing data. Always ask if one is available, or do an online search if the data is public.</p>
<p class="indent">In this set of census data, and thus the table you just made, each row describes the demographics of one county, starting with its <span class="literal">geo_name</span> <span class="ent">➊</span> and its two-character state abbreviation, the <span class="literal">state_us_abbreviation</span> <span class="ent">➋</span>. Because both are text, we store them as <span class="literal">varchar</span>. The data dictionary indicates that the maximum length of the <span class="literal">geo_name</span> field is 90 characters, but because most names are shorter, using <span class="literal">varchar</span> will conserve space if we fill the field with a shorter name, such as <span class="literal">Lee County</span>, while allowing us to specify the maximum 90 characters.</p>
<p class="indent">The geography, or summary level, represented by each row is described by <span class="literal">summary_level</span> <span class="ent">➌</span>. We’re working only with county-level data, so the code is the same for each row: <span class="literal">050</span>. Even though that code resembles a number, we’re treating it as text by again using <span class="literal">varchar</span>. If we used an integer type, that leading <span class="literal">0</span> would be stripped on import, leaving <span class="literal">50</span>. We don’t want to do that because <span class="literal">050</span> is the complete summary level code, and we’d be altering the meaning of the data if the leading <span class="literal">0</span> were lost. Also, we won’t be doing any math with this value.</p>
<p class="indent"><span epub:type="pagebreak" id="page_46"/>Numbers from 0 to 9 in <span class="literal">region</span> and <span class="literal">division</span> <span class="ent">➍</span> represent the location of a county in the United States, such as the Northeast, Midwest, or South Atlantic. No number is higher than 9, so we define the columns with type <span class="literal">smallint</span>. We again use <span class="literal">varchar</span> for <span class="literal">state_fips</span> and <span class="literal">county_fips</span>, which are the standard federal codes for those entities, because those codes contain leading zeros that should not be stripped. It’s always important to distinguish codes from numbers; these state and county values are actually labels as opposed to numbers used for math.</p>
<p class="indent">The number of square meters for land and water in the county are recorded in <span class="literal">area_land</span> and <span class="literal">area_water</span> <span class="ent">➎</span>, respectively. In certain places—such as Alaska, where there’s lots of land to go with all that snow—some values easily surpass the <span class="literal">integer</span> type’s maximum of 2,147,483,648. For that reason, we’re using <span class="literal">bigint</span>, which will handle the 376,855,656,455 square meters in the Yukon-Koyukuk Census Area with room to spare.</p>
<p class="indent">Next, <span class="literal">population_count_100_percent</span> and <span class="literal">housing_unit_count_100_percent</span> <span class="ent">➏</span> are the total counts of population and housing units in the geography. In 2010, the United States had 308.7 million people and 131.7 million housing units. The population and housing units for any county fits well within the <span class="literal">integer</span> data type’s limits, so we use that for both.</p>
<p class="indent">The latitude and longitude of a point near the center of the county, called an <em>internal point</em>, are specified in <span class="literal">internal_point_lat</span> and <span class="literal">internal_point_lon</span> <span class="ent">➐</span>, respectively. The Census Bureau—along with many mapping systems—expresses latitude and longitude coordinates using a <em>decimal degrees</em> system. <em>Latitude</em> represents positions north and south on the globe, with the equator at 0 degrees, the North Pole at 90 degrees, and the South Pole at −90 degrees.</p>
<p class="indent"><em>Longitude</em> represents locations east and west, with the <em>Prime Meridian</em> that passes through Greenwich in London at 0 degrees longitude. From there, longitude increases both east and west (positive numbers to the east and negative to the west) until they meet at 180 degrees on the opposite side of the globe. The location there, known as the <em>antimeridian</em>, is used as the basis for the <em>International Date Line</em>.</p>
<p class="indent">When reporting interior points, the Census Bureau uses up to seven decimal places. With a value up to 180 to the left of the decimal, we need to account for a maximum of 10 digits total. So, we’re using <span class="literal">numeric</span> with a precision of <span class="literal">10</span> and a scale of <span class="literal">7</span>.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>PostgreSQL, through the PostGIS extension, can store geometric data, which includes points that represent latitude and longitude in a single column. We’ll explore geometric data when we cover geographical queries in <a href="ch14.xhtml#ch14">Chapter 14</a>.</em></p>
</div>
<p class="indent">Finally, we reach a series of columns <span class="ent">➑</span> that contain iterations of the population counts by race and ethnicity for the county as well as housing unit counts. The full set of 2010 Census data contains 291 of these columns. I’ve pared that down to 78 for this exercise, omitting many of the columns to make the data set more compact for these exercises.</p>
<p class="indent">I won’t discuss all the columns now, but <a href="ch04.xhtml#ch04tab1">Table 4-1</a> shows a small sample.</p>
<p class="tabcap" id="ch04tab1"><span epub:type="pagebreak" id="page_47"/><strong>Table 4-1:</strong> Census Population-Count Columns</p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Column name</strong></p></td>
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Description</strong></p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010001</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Total population</p></td>
</tr>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010002</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Population of one race</p></td>
</tr>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010003</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Population of one race: White alone</p></td>
</tr>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010004</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Population of one race: Black or African American alone</p></td>
</tr>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010005</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Population of one race: American Indian and Alaska Native alone</p></td>
</tr>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010006</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Population of one race: Asian alone</p></td>
</tr>
<tr>
<td class="table-c" style="vertical-align: top;"><p class="taba"><span class="literal">p0010007</span></p></td>
<td class="table-c" style="vertical-align: top;"><p class="taba">Population of one race: Native Hawaiian and Other Pacific Islander alone</p></td>
</tr>
<tr>
<td class="table-ca" style="vertical-align: top;"><p class="taba"><span class="literal">p0010008</span></p></td>
<td class="table-ca" style="vertical-align: top;"><p class="taba">Population of one race: Some Other Race alone</p></td>
</tr>
</tbody>
</table>
<p class="indent">You’ll explore this data more in the next chapter when we look at math with SQL. For now, let’s run the import.</p>
<h4 class="h4" id="lev54"><em>Performing the Census Import with COPY</em></h4>
<p class="noindent">Now you’re ready to bring the census data into the table. Run the code in <a href="ch04.xhtml#ch04list3">Listing 4-3</a>, remembering to change the path to the file to match the location of the data on your computer:</p>
<p class="programs">COPY us_counties_2010<br/>FROM '<em>C:\YourDirectory\</em>us_counties_2010.csv'<br/>WITH (FORMAT CSV, HEADER);</p>
<p class="listing" id="ch04list3"><em>Listing 4-3: Importing census data using <span class="literal">COPY</span></em></p>
<p class="indent">When the code executes, you should see the following message in pgAdmin:</p>
<p class="programs">Query returned successfully: 3143 rows affected</p>
<p class="indent">That’s good news: the import CSV has the same number of rows. If you have an issue with the source CSV or your import statement, the database will throw an error. For example, if one of the rows in the CSV had more columns than in the target table, you’d see an error message that provides a hint as to how to fix it:</p>
<p class="programs">ERROR: extra data after last expected column<br/>SQL state: 22P04<br/>Context: COPY us_counties_2010, line 2: "Autauga County,AL,050,3,6,01,001 ..."</p>
<p class="indent">Even if no errors are reported, it’s always a good idea to visually scan the data you just imported to ensure everything looks as expected. Start with a <span class="literal">SELECT</span> query of all columns and rows:</p>
<p class="programs">SELECT * FROM us_counties_2010;</p>
<p class="indent"><span epub:type="pagebreak" id="page_48"/>There should be 3,143 rows displayed in pgAdmin, and as you scroll left and right through the result set, each field should have the expected values. Let’s review some columns that we took particular care to define with the appropriate data types. For example, run the following query to show the counties with the largest <span class="literal">area_land</span> values. We’ll use a <span class="literal">LIMIT</span> clause, which will cause the query to only return the number of rows we want; here, we’ll ask for three:</p>
<p class="programs">SELECT geo_name, state_us_abbreviation, area_land<br/>FROM us_counties_2010<br/>ORDER BY area_land DESC<br/>LIMIT 3;</p>
<p class="indent">This query ranks county-level geographies from largest land area to smallest in square meters. We defined <span class="literal">area_land</span> as <span class="literal">bigint</span> because the largest values in the field are bigger than the upper range provided by regular <span class="literal">integer</span>. As you might expect, big Alaskan geographies are at the top:</p>
<p class="programs">geo_name                     state_us_abbreviation    area_land<br/>-------------------------    ---------------------    ------------<br/>Yukon-Koyukuk Census Area    AK                       376855656455<br/>North Slope Borough          AK                       229720054439<br/>Bethel Census Area           AK                       105075822708</p>
<p class="indent">Next, check the latitude and longitude columns of <span class="literal">internal_point_lat</span> and <span class="literal">internal_point_lon</span>, which we defined with <span class="literal">numeric(10,7)</span>. This code sorts the counties by longitude from the greatest to smallest value. This time, we’ll use <span class="literal">LIMIT</span> to retrieve five rows:</p>
<p class="programs">SELECT geo_name, state_us_abbreviation, internal_point_lon<br/>FROM us_counties_2010<br/>ORDER BY internal_point_lon DESC<br/>LIMIT 5;</p>
<p class="indent">Longitude measures locations from east to west, with locations west of the Prime Meridian in England represented as negative numbers starting with −1, −2, −3, and so on the farther west you go. We sorted in descending order, so we’d expect the easternmost counties of the United States to show at the top of the query result. Instead—surprise!—there’s a lone Alaska geography at the top:</p>
<div class="image"><img alt="image" src="../images/prog_page_48.jpg"/></div>
<p class="indent"><span epub:type="pagebreak" id="page_49"/>Here’s why: the Alaskan Aleutian Islands extend so far west (farther west than Hawaii) that they cross the antimeridian at 180 degrees longitude by less than 2 degrees. Once past the antimeridian, longitude turns positive, counting back down to 0. Fortunately, it’s not a mistake in the data; however, it’s a fact you can tuck away for your next trivia team competition.</p>
<p class="indent">Congratulations! You have a legitimate set of government demographic data in your database. I’ll use it to demonstrate exporting data with <span class="literal">COPY</span> later in this chapter, and then you’ll use it to learn math functions in <a href="ch05.xhtml#ch05">Chapter 5</a>. Before we move on to exporting data, let’s examine a few additional importing techniques.</p>
<h3 class="h3" id="lev55">Importing a Subset of Columns with COPY</h3>
<p class="noindent">If a CSV file doesn’t have data for all the columns in your target database table, you can still import the data you have by specifying which columns are present in the data. Consider this scenario: you’re researching the salaries of all town supervisors in your state so you can analyze government spending trends by geography. To get started, you create a table called <span class="literal">supervisor_salaries</span> with the code in <a href="ch04.xhtml#ch04list4">Listing 4-4</a>:</p>
<p class="programs">CREATE TABLE supervisor_salaries (<br/>    town varchar(30),<br/>    county varchar(30),<br/>    supervisor varchar(30),<br/>    start_date date,<br/>    salary money,<br/>    benefits money<br/>);</p>
<p class="listing" id="ch04list4"><em>Listing 4-4: Creating a table to track supervisor salaries</em></p>
<p class="indent">You want columns for the town and county, the supervisor’s name, the date he or she started, and salary and benefits (assuming you just care about current levels). However, the first county clerk you contact says, “Sorry, we only have town, supervisor, and salary. You’ll need to get the rest from elsewhere.” You tell them to send a CSV anyway. You’ll import what you can.</p>
<p class="indent">I’ve included such a sample CSV you can download in the book’s resources at <em><a href="https://www.nostarch.com/practicalSQL/">https://www.nostarch.com/practicalSQL/</a></em>, called <em>supervisor_salaries.csv</em>. You could try to import it using this basic <span class="literal">COPY</span> syntax:</p>
<p class="programs">COPY supervisor_salaries<br/>FROM '<em>C:\YourDirectory\</em>supervisor_salaries.csv'<br/>WITH (FORMAT CSV, HEADER);</p>
<p class="indent">But if you do, PostgreSQL will return an error:</p>
<p class="programs">********** Error **********<br/>ERROR: missing data for column "start_date"<br/>SQL state: 22P04<br/>Context: COPY supervisor_salaries, line 2: "Anytown,Jones,27000"</p>
<p class="indent"><span epub:type="pagebreak" id="page_50"/>The database complains that when it got to the fourth column of the table, <span class="literal">start_date</span>, it couldn’t find any data in the CSV. The workaround for this situation is to tell the database which columns in the table are present in the CSV, as shown in <a href="ch04.xhtml#ch04list5">Listing 4-5</a>:</p>
<p class="programs">COPY supervisor_salaries <span class="ent">➊</span>(town, supervisor, salary)<br/>FROM '<em>C:\YourDirectory\</em>supervisor_salaries.csv'<br/>WITH (FORMAT CSV, HEADER);</p>
<p class="listing" id="ch04list5"><em>Listing 4-5: Importing salaries data from CSV to three table columns</em></p>
<p class="indent">By noting in parentheses <span class="ent">➊</span> the three present columns after the table name, we tell PostgreSQL to only look for data to fill those columns when it reads the CSV. Now, if you select the first couple of rows from the table, you’ll see only those columns filled:</p>
<div class="image"><img alt="image" src="../images/prog_page_50.jpg"/></div>
<h3 class="h3" id="lev56">Adding a Default Value to a Column During Import</h3>
<p class="noindent">What if you want to populate the <span class="literal">county</span> column during the import, even though the value is missing from the CSV file? You can do so by using a <em>temporary table</em>. Temporary tables exist only until you end your database session. When you reopen the database (or lose your connection), those tables disappear. They’re handy for performing intermediary operations on data as part of your processing pipeline; we’ll use one to add a county name to the <span class="literal">supervisor_salaries</span> table as we import the CSV.</p>
<p class="indent">Start by clearing the data you already imported into <span class="literal">supervisor_salaries</span> using a <span class="literal">DELETE</span> query:</p>
<p class="programs">DELETE FROM supervisor_salaries;</p>
<p class="indent">When that query finishes, run the code in <a href="ch04.xhtml#ch04list6">Listing 4-6</a>:</p>
<p class="programs"><span class="ent">➊</span> CREATE TEMPORARY TABLE supervisor_salaries_temp (LIKE supervisor_salaries);<br/><br/><span class="ent">➋</span> COPY supervisor_salaries_temp (town, supervisor, salary)<br/>  FROM '<em>C:\YourDirectory\</em>supervisor_salaries.csv'<br/>  WITH (FORMAT CSV, HEADER);<br/><br/><span class="ent">➌</span> INSERT INTO supervisor_salaries (town, county, supervisor, salary)<br/>  SELECT town, 'Some County', supervisor, salary<br/>  FROM supervisor_salaries_temp;<br/><br/><span class="ent">➍</span> DROP TABLE supervisor_salaries_temp;</p>
<p class="listing" id="ch04list6"><em>Listing 4-6: Using a temporary table to add a default value to a column during import</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_51"/>This script performs four tasks. First, we create a temporary table called <span class="literal">supervisor_salaries_temp</span> <span class="ent">➊</span> based on the original <span class="literal">supervisor_salaries</span> table by passing as an argument the <span class="literal">LIKE</span> keyword (covered in “Using <span class="literal">LIKE</span> and <span class="literal">ILIKE</span> with <span class="literal">WHERE</span>” on <a href="ch02.xhtml#page_19">page 19</a>) followed by the parent table to copy. Then we import the <em>supervisor_salaries.csv</em> file <span class="ent">➋</span> into the temporary table using the now-familiar <span class="literal">COPY</span> syntax.</p>
<p class="indent">Next, we use an <span class="literal">INSERT</span> statement to fill the salaries table <span class="ent">➌</span>. Instead of specifying values, we employ a <span class="literal">SELECT</span> statement to query the temporary table. That query specifies the value for the second column, not as a column name, but as a string inside single quotes.</p>
<p class="indent">Finally, we use <span class="literal">DROP TABLE</span> to erase the temporary table <span class="ent">➍</span>. The temporary table will automatically disappear when you disconnect from the PostgreSQL session, but this removes it now in case we want to run the query again against another CSV.</p>
<p class="indent">After you run the query, run a <span class="literal">SELECT</span> statement on the first couple of rows to see the effect:</p>
<div class="image"><img alt="image" src="../images/prog_page_51.jpg"/></div>
<p class="indent">Now you’ve filled the <span class="literal">county</span> field with a value. The path to this import might seem laborious, but it’s instructive to see how data processing can require multiple steps to get the desired results. The good news is that this temporary table demo is an apt indicator of the flexibility SQL offers to control data handling.</p>
<h3 class="h3" id="lev57">Using COPY to Export Data</h3>
<p class="noindent">The main difference between exporting and importing data with <span class="literal">COPY</span> is that rather than using <span class="literal">FROM</span> to identify the source data, you use <span class="literal">TO</span> for the path and name of the output file. You control how much data to export—an entire table, just a few columns, or to fine-tune it even more, the results of a query.</p>
<p class="indent">Let’s look at three quick examples.</p>
<h4 class="h4" id="lev58"><em>Exporting All Data</em></h4>
<p class="noindent">The simplest export sends everything in a table to a file. Earlier, you created the table <span class="literal">us_counties_2010</span> with 91 columns and 3,143 rows of census data. The SQL statement in <a href="ch04.xhtml#ch04list7">Listing 4-7</a> exports all the data to a text file named <em>us_counties_export.txt</em>. The <span class="literal">WITH</span> keyword option tells PostgreSQL to include a header row and use the pipe symbol instead of a comma for a delimiter. I’ve used the <em>.txt</em> file extension here for two reasons. First, it demonstrates that you can export to any text file format; second, we’re using a pipe for a delimiter, not a comma. I like to avoid calling files <em>.csv</em> unless they truly have commas as a separator.</p>
<p class="indent"><span epub:type="pagebreak" id="page_52"/>Remember to change the output directory to your preferred location.</p>
<p class="programs">COPY us_counties_2010<br/>TO '<em>C:\YourDirectory\</em>us_counties_export.txt'<br/>WITH (FORMAT CSV, HEADER, DELIMITER '|');</p>
<p class="listing" id="ch04list7"><em>Listing 4-7: Exporting an entire table with <span class="literal">COPY</span></em></p>
<h4 class="h4" id="lev59"><em>Exporting Particular Columns</em></h4>
<p class="noindent">You don’t always need (or want) to export all your data: you might have sensitive information, such as Social Security numbers or birthdates, that need to remain private. Or, in the case of the census county data, maybe you’re working with a mapping program and only need the county name and its geographic coordinates to plot the locations. We can export only these three columns by listing them in parentheses after the table name, as shown in <a href="ch04.xhtml#ch04list8">Listing 4-8</a>. Of course, you must enter these column names precisely as they’re listed in the data for PostgreSQL to recognize them.</p>
<p class="programs">COPY us_counties_2010 (geo_name, internal_point_lat, internal_point_lon)<br/>TO '<em>C:\YourDirectory\</em>us_counties_latlon_export.txt'<br/>WITH (FORMAT CSV, HEADER, DELIMITER '|');</p>
<p class="listing" id="ch04list8"><em>Listing 4-8: Exporting selected columns from a table with <span class="literal">COPY</span></em></p>
<h4 class="h4" id="lev60"><em>Exporting Query Results</em></h4>
<p class="noindent">Additionally, you can add a query to <span class="literal">COPY</span> to fine-tune your output. In <a href="ch04.xhtml#ch04list9">Listing 4-9</a> we export the name and state abbreviation of only those counties whose name contains the letters <span class="literal">mill</span> in either uppercase or lowercase by using the case-insensitive <span class="literal">ILIKE</span> and the <span class="literal">%</span> wildcard character we covered in “Using <span class="literal">LIKE</span> and <span class="literal">ILIKE</span> with <span class="literal">WHERE</span>” on <a href="ch02.xhtml#page_19">page 19</a>.</p>
<p class="programs">COPY (<br/>    SELECT geo_name, state_us_abbreviation<br/>    FROM us_counties_2010<br/>    WHERE geo_name ILIKE '%mill%'<br/>     )<br/>TO '<em>C:\YourDirectory\</em>us_counties_mill_export.txt'<br/>WITH (FORMAT CSV, HEADER, DELIMITER '|');</p>
<p class="listing" id="ch04list9"><em>Listing 4-9: Exporting query results with <span class="literal">COPY</span></em></p>
<p class="indent">After running the code, your output file should have nine rows with county names including Miller, Roger Mills, and Vermillion.</p>
<h3 class="h3" id="lev61">Importing and Exporting Through pgAdmin</h3>
<p class="noindent">At times, the SQL <span class="literal">COPY</span> commands won’t be able to handle certain imports and exports, typically when you’re connected to a PostgreSQL instance <span epub:type="pagebreak" id="page_53"/>running on a computer other than yours, perhaps elsewhere on a network. When that happens, you might not have access to that computer’s filesystem, which makes setting the path in the <span class="literal">FROM</span> or <span class="literal">TO</span> clause difficult.</p>
<p class="indent">One workaround is to use pgAdmin’s built-in import/export wizard. In pgAdmin’s object browser (the left vertical pane), locate the list of tables in your <span class="literal">analysis</span> database by choosing <strong>Databases <span class="ent">▸</span> analysis <span class="ent">▸</span> Schemas <span class="ent">▸</span> public <span class="ent">▸</span> Tables</strong>.</p>
<p class="indent">Next, right-click on the table you want to import to or export from, and select <strong>Import/Export</strong>. A dialog appears that lets you choose either to import or export from that table, as shown in <a href="ch04.xhtml#ch04fig1">Figure 4-1</a>.</p>
<div class="image"><a id="ch04fig1"/><img alt="image" src="../images/f0053-01.jpg"/></div>
<p class="figcap"><em>Figure 4-1: The pgAdmin Import/Export dialog</em></p>
<p class="indent">To import, move the Import/Export slider to <strong>Import</strong>. Then click the three dots to the right of the <strong>Filename</strong> box to locate your CSV file. From the Format drop-down list, choose <strong>csv</strong>. Then adjust the header, delimiter, quoting, and other options as needed. Click <strong>OK</strong> to import the data.</p>
<p class="indent">To export, use the same dialog and follow similar steps.</p>
<h3 class="h3" id="lev62">Wrapping Up</h3>
<p class="noindent">Now that you’ve learned how to bring external data into your database, you can start digging into a myriad of data sets, whether you want to explore one of the thousands of publicly available data sets, or data related to your own career or studies. Plenty of data is available in CSV format or a format easily convertible to CSV. Look for data dictionaries to help you understand the data and choose the right data type for each field.</p>
<p class="indent">The census data you imported as part of this chapter’s exercises will play a starring role in the next chapter in which we explore math functions with SQL.</p>
<div class="sidebar" id="ch04sb1">
<p class="sidebart"><span epub:type="pagebreak" id="page_54"/><strong>TRY IT YOURSELF</strong></p>
<p class="spara">Continue your exploration of data import and export with these exercises. Remember to consult the PostgreSQL documentation at <em><a href="https://www.postgresql.org/docs/current/static/sql-copy.html">https://www.postgresql.org/docs/current/static/sql-copy.html</a></em> for hints:</p>
<ol>
<li class="noindent"><p class="list">Write a <span class="literal">WITH</span> statement to include with <span class="literal">COPY</span> to handle the import of an imaginary text file whose first couple of rows look like this:</p>
<p class="programs">id:movie:actor<br/>50:#Mission: Impossible#:Tom Cruise</p></li>
<li class="noindent"><p class="list">Using the table <span class="literal">us_counties_2010</span> you created and filled in this chapter, export to a CSV file the 20 counties in the United States that have the most housing units. Make sure you export only each county’s name, state, and number of housing units. (Hint: Housing units are totaled for each county in the column <span class="literal">housing_unit_count_100_percent</span>.)</p></li>
<li class="noindent"><p class="list">Imagine you’re importing a file that contains a column with these values:</p>
<p class="programs">17519.668<br/>20084.461<br/>18976.335</p></li>
</ol>
<p class="spara1">Will a column in your target table with data type <span class="literal">numeric(3,8)</span> work for these values? Why or why not?</p>
</div>
</body>
</html>